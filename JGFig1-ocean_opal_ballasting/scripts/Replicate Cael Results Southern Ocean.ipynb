{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import Packages and Modules*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "from matplotlib import *\n",
    "from netCDF4 import Dataset\n",
    "from scipy import stats\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from pylr2 import regress2\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import csv\n",
    "import statistics\n",
    "from major_axis_regression import regress2\n",
    "from parula import parula\n",
    "# parula is a .py file that should be found in script that adds parula, the same colour scale as Cael uses to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parula_map = parula()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### *Import Data*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forjoesouth = np.loadtxt(open(\"../data/forjoesouth.csv\"), delimiter=\",\") # imports Cael's data for the Southern Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forjoesouth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists which indexes are which variables\n",
    "bb_depths_so = forjoesouth[:,0]\n",
    "bb_Foc_so = forjoesouth[:,3]\n",
    "bb_Fic_so = forjoesouth[:,4]\n",
    "bb_Fsi_so = forjoesouth[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JG_BBCael(data,bbeta,data_no,bbeta_pair_no):\n",
    "    import statsmodels.api as sm\n",
    "    import numpy as np \n",
    "\n",
    "    # find random coordinate points for SO \n",
    "\n",
    "    index_number = np.random.randint(0, high=768, size=data_no)        \n",
    "    \n",
    "    #print('average in mask:', np.average(new_mask))\n",
    "    # this average should be 1 == only areas with values are selected\n",
    "    #print('(should be one or else something went wrong)')\n",
    "\n",
    "    # use randomly selected coordinate points to select 10000 random values of Foc, Fic and Fsi \n",
    "    random_depth = data[index_number,0]\n",
    "    random_Foc = data[index_number, 3]\n",
    "    random_Fic = data[index_number, 4]\n",
    "    random_Fsi = data[index_number, 5]\n",
    "    \n",
    "    #y = np.power((random_depth[:, np.newaxis]/1000), bbeta[:, 0])\n",
    "    #y = np.log((random_Foc[:, np.newaxis] * y))\n",
    "    #x = np.log((random_Fic[:, np.newaxis]) + (bbeta[:, 1] * random_Fsi[:, np.newaxis]))\n",
    "\n",
    "    y = np.log(random_Foc[:, np.newaxis]) + (bbeta[:, 0] * np.subtract(np.log(random_depth[:, np.newaxis]),np.log(1000)))\n",
    "    x = np.log((random_Fic[:, np.newaxis]) + (bbeta[:, 1] * random_Fsi[:, np.newaxis]))\n",
    "\n",
    "    \n",
    "    r_squared = np.ones((bbeta_pair_no))*np.nan\n",
    "    slope = np.ones((bbeta_pair_no))*np.nan\n",
    "    intercept = np.ones((bbeta_pair_no))*np.nan\n",
    "\n",
    "    for i in np.arange(0,bbeta_pair_no,1):\n",
    "        r_squared[i], slope[i], intercept[i] = regress2(x[:,i], y[:,i], _method_type_2=\"major axis\")\n",
    "\n",
    "    r_maximum = np.nanmax(r_squared)\n",
    "\n",
    "    where_max = np.where(r_squared==r_maximum)\n",
    "\n",
    "    b_maxr = np.nanmean(bbeta[where_max, 0])\n",
    "    beta_maxr = np.nanmean(bbeta[where_max, 1])\n",
    "    slope_max = np.nanmean(slope[where_max])\n",
    "    intercept_max = np.nanmean(intercept[where_max])\n",
    "\n",
    "    return r_maximum, b_maxr, beta_maxr, slope_max, intercept_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Create the b and beta range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we create b and beta range to search for in each sample taken. \n",
    "# these are estimated from a small b and beta sample. \n",
    "# later we ensure that the data isn't skewed to one side of the distribution searched within b and beta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "# define b and beta\n",
    "b = numpy.arange(0.4, 1, 0.02)\n",
    "beta = numpy.arange(0.01,  0.5, 0.02)\n",
    "\n",
    "# define number of searches within b and beta (for histograms later)\n",
    "b_bins = (1-0.4)/0.05\n",
    "beta_bins = 0.5/0.005\n",
    "\n",
    "# this calculates the number of b/beta unique combinations\n",
    "bbeta = np.array(list(itertools.product(b, beta)))\n",
    "bbeta_pair_no = int((bbeta[:,1].shape)[0])\n",
    "print(bbeta_pair_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### *Run Regression*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 768 # this is the number of samples taken each time (ideally the same as the size of the dataset)\n",
    "resamples = 1000 # this is the number of bootstrap resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we initiate the variables\n",
    "r_maximum = np.ones((resamples))*np.nan\n",
    "b_maxr = np.ones((resamples))*np.nan\n",
    "beta_maxr = np.ones((resamples))*np.nan\n",
    "slope_max = np.ones((resamples))*np.nan\n",
    "intercept_max = np.ones((resamples))*np.nan\n",
    "random_Fic = np.ones((resamples,n))*np.nan\n",
    "random_Foc = np.ones((resamples,n))*np.nan\n",
    "random_Fsi = np.ones((resamples,n))*np.nan\n",
    "random_depth = np.ones((resamples, n))*np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "/gpfs/scratch/mep22dku/CaelJG-intercomparison/JGFig1-ocean_opal_ballasting/scripts/major_axis_regression.py:125: RuntimeWarning: invalid value encountered in subtract\n",
      "  xp = _x - xm\n",
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: All-NaN slice encountered\n",
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/ipykernel_launcher.py:38: RuntimeWarning: Mean of empty slice\n",
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: Mean of empty slice\n",
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: Mean of empty slice\n",
      "/gpfs/home/mep22dku/.conda/envs/swamp2/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :    0.21254229545593262\n",
      "100 :     24.778528690338135\n",
      "500 :     171.67560386657715\n"
     ]
    }
   ],
   "source": [
    "# here we run through the function which finds the best fit of b and beta of the range given\n",
    "# we do this as many times as given in the resamples (usually at least as many data points)\n",
    "\n",
    "for i in np.arange(0,resamples,1):\n",
    "    w = time.time()\n",
    "    r_maximum[i], b_maxr[i], beta_maxr[i], slope_max[i], intercept_max[i] = \\\n",
    "    JG_BBCael(forjoesouth,bbeta,n,bbeta_pair_no)\n",
    "    if i == 1:\n",
    "        w1 = time.time()\n",
    "        print(i, ':   ', w1-w)\n",
    "    if i == 100:\n",
    "        w2=time.time()\n",
    "        print(i, ':    ', w2-w1)\n",
    "    if i == 500:\n",
    "        w3=time.time()\n",
    "        print(i, ':    ', w3-w2)\n",
    "    if i == 999:\n",
    "        w4=time.time()\n",
    "        print(i, ':    ', w4-w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Plot Histograms\n",
    "here we're looking to make sure that the searches for b and beta don't fall at the edges of the search limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(b_maxr, range=(0.00, 1), bins=int(b_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(beta_maxr, range=(0.02, 2), bins=int(beta_bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Create median values for plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find median values of the best fit regressions\n",
    "\n",
    "r_median = np.nanmedian(r_maximum)\n",
    "b_median = np.nanmedian(b_maxr)\n",
    "beta_median = np.nanmedian(beta_maxr)\n",
    "intercept_median = np.nanmedian(intercept_max)\n",
    "slope_median = np.nanmedian(slope_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate alpha(si) and alpha(ic) values from the median beta, intercept and slope values\n",
    "where kappa = e^intercept and gamma = slope of the line\n",
    "\n",
    "y = Foc(z/1000)\n",
    "\n",
    "x = Fic * beta(Fsi))^gamma\n",
    "\n",
    "and: beta is ~ to a_si/a_ic\n",
    "\n",
    "### therefore:\n",
    "\n",
    "if: y = k * (beta * x^gamma)\n",
    "\n",
    "beta = alpha_si/alpha_ic\n",
    "\n",
    "alpha_ic = kappa^(1/gamma)\n",
    "\n",
    "alpha_si = beta * kappa^(1/gamma)\n",
    "\n",
    "k(kappa) = e^(intercept) and gamma = slope\n",
    "\n",
    "the equation becomes Foc = (alpha_ic Fic + alpha_si Fsi)^gamma (z/1000)^b. so beta = alpha_si/alpha_ic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = np.exp(intercept_max)\n",
    "kappa_median = np.nanmedian(np.exp(intercept_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ic_1 = kappa**(1/slope_median)\n",
    "a_si_1 = beta_median*kappa**(1/slope_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ic = kappa_median**(1/slope_median)\n",
    "a_si = beta_median*kappa_median**(1/slope_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_ic)\n",
    "print(a_si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2:        ', r_median)\n",
    "print('b:         ', b_median)\n",
    "print('a_ic:      ', a_ic)\n",
    "print('a_si:      ', a_si)\n",
    "print('intercept: ', intercept_median)\n",
    "print('slope:     ', slope_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Create values for plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forjoesouth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y = np.log(forjoesouth[:,3]) + (b_median * np.subtract(np.log(forjoesouth[:,0]),np.log(1000)))\n",
    "log_x = np.log(kappa_median**slope_median*((forjoesouth[:,4]) + (beta_median * forjoesouth[:,5])))\n",
    "\n",
    "y = np.exp(log_y)\n",
    "x = np.exp(log_x)\n",
    "\n",
    "scale = forjoesouth[:,4] / forjoesouth[:,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_line = [0.00001, np.max(x)+10000]\n",
    "y_line = kappa_median*x_line**slope_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "plt.plot(x_line, y_line, color='black', ls='-.', lw=2)\n",
    "g = ax.scatter(x, y, c=scale, cmap=parula_map, norm=matplotlib.colors.LogNorm(vmin=0.01, vmax=100), s=40)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "#plt.ylim(1e-2, 316.227766017)\n",
    "#plt.xlim(0.00316227766, 600)\n",
    "#axis([.005 500 .005 500])\n",
    "plt.ylim(.005, 500)\n",
    "plt.xlim(.005, 500)\n",
    "cbar = plt.colorbar(g)\n",
    "\n",
    "plt.title(r'$Southern \\ Ocean \\ (r^{2} = 0.89)$', size=16)\n",
    "\n",
    "plt.ylabel(r'$F_{oc}\\left ({z}  \\right )^{0.67} \\ (mg \\ m^{-2} \\ d^{-1})$', size=12) \n",
    "\n",
    "plt.xlabel(r'$(1.15 \\times F_{ic}) + (0.195 \\times F_{si})$', size=12)\n",
    "\n",
    "cbar.set_label(r'${F_{ic}} \\ / \\ {F_{si}}$', size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
